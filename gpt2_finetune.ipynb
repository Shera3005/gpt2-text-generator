{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d5a6fc0fd3c543e09f1c7f7a12612632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bfb97f5e95947fe982ca3efc0f871ef",
              "IPY_MODEL_c197de34198e4ccf972bf5b598411be2",
              "IPY_MODEL_78d64a11f2e840b991b7a3dbd7a53b52"
            ],
            "layout": "IPY_MODEL_80083c83890a49249ef1eff11bf0b9ef"
          }
        },
        "3bfb97f5e95947fe982ca3efc0f871ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42bba6550f29450e84743a9595ffbb0f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8327dbf52b13416fae7be76965eae2de",
            "value": "Map:‚Äá100%"
          }
        },
        "c197de34198e4ccf972bf5b598411be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_791e3c1f8e104f92ae82f29eaa8f6380",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_356928027b664a8d833987bb392dbabe",
            "value": 10
          }
        },
        "78d64a11f2e840b991b7a3dbd7a53b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdc9b2074c0443ff93186e58a36b4546",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7042ada0a87c4c419ed6ddb5f6ca0971",
            "value": "‚Äá10/10‚Äá[00:00&lt;00:00,‚Äá374.76‚Äáexamples/s]"
          }
        },
        "80083c83890a49249ef1eff11bf0b9ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42bba6550f29450e84743a9595ffbb0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8327dbf52b13416fae7be76965eae2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "791e3c1f8e104f92ae82f29eaa8f6380": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "356928027b664a8d833987bb392dbabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdc9b2074c0443ff93186e58a36b4546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7042ada0a87c4c419ed6ddb5f6ca0971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install required packages\n",
        "!pip install -q transformers datasets\n",
        "\n",
        "# STEP 2: Import libraries\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "from datasets import Dataset\n",
        "\n",
        "# STEP 3: Load pre-trained GPT-2\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "# STEP 4: Create sample training text\n",
        "sample_text = \"\"\"\n",
        "Once upon a time, there was a kingdom where machines could think and speak.\n",
        "These machines learned from books, the internet, and conversations with people.\n",
        "GPT-2 was one such machine that could write amazing stories and complete sentences logically.\n",
        "Its creators fine-tuned it using lots of custom data to improve its results.\n",
        "Artificial Intelligence grew smarter every day, with new models learning new skills.\n",
        "In a classroom, a teacher used GPT-2 to help students write better essays.\n",
        "The model analyzed grammar, style, and helped organize thoughts clearly.\n",
        "By feeding GPT-2 lots of high-quality text, it learned how to imitate it in return.\n",
        "Researchers even used it to create poetry, jokes, and technical writing.\n",
        "GPT-2 proved that with the right data, language models could become very powerful tools.\n",
        "\"\"\"\n",
        "\n",
        "# STEP 5: Convert text into HuggingFace Dataset object\n",
        "lines = sample_text.strip().split(\"\\n\")\n",
        "dataset = Dataset.from_dict({\"text\": lines})\n",
        "\n",
        "# STEP 6: Tokenize the text\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], return_special_tokens_mask=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# STEP 7 (Final Fix): Manually group tokens into blocks\n",
        "block_size = 128\n",
        "\n",
        "# Flatten all input_ids into one list\n",
        "all_input_ids = sum(tokenized_dataset[\"input_ids\"], [])\n",
        "\n",
        "# Trim to block size multiple\n",
        "total_length = (len(all_input_ids) // block_size) * block_size\n",
        "all_input_ids = all_input_ids[:total_length]\n",
        "\n",
        "# Split into chunks\n",
        "input_ids = [all_input_ids[i:i + block_size] for i in range(0, total_length, block_size)]\n",
        "attention_mask = [[1] * block_size] * len(input_ids)\n",
        "\n",
        "# Build grouped dataset\n",
        "from datasets import Dataset\n",
        "lm_dataset = Dataset.from_dict({\n",
        "    \"input_ids\": input_ids,\n",
        "    \"attention_mask\": attention_mask\n",
        "})\n",
        "\n",
        "\n",
        "# STEP 8: Set training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-finetuned\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    save_steps=500,\n",
        "    save_total_limit=1,\n",
        "    logging_steps=100,\n",
        "    prediction_loss_only=True\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# STEP 9: Train the model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=lm_dataset,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# STEP 10: Save the model\n",
        "trainer.save_model(\"./gpt2-finetuned\")\n",
        "tokenizer.save_pretrained(\"./gpt2-finetuned\")\n",
        "\n",
        "print(\"‚úÖ Training complete and model saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125,
          "referenced_widgets": [
            "d5a6fc0fd3c543e09f1c7f7a12612632",
            "3bfb97f5e95947fe982ca3efc0f871ef",
            "c197de34198e4ccf972bf5b598411be2",
            "78d64a11f2e840b991b7a3dbd7a53b52",
            "80083c83890a49249ef1eff11bf0b9ef",
            "42bba6550f29450e84743a9595ffbb0f",
            "8327dbf52b13416fae7be76965eae2de",
            "791e3c1f8e104f92ae82f29eaa8f6380",
            "356928027b664a8d833987bb392dbabe",
            "bdc9b2074c0443ff93186e58a36b4546",
            "7042ada0a87c4c419ed6ddb5f6ca0971"
          ]
        },
        "id": "stKbaJ6TsYQF",
        "outputId": "99f13f67-8378-4926-9fe0-3f28c7036e71"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5a6fc0fd3c543e09f1c7f7a12612632"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:25, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Training complete and model saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./gpt2-finetuned\")\n",
        "tokenizer.save_pretrained(\"./gpt2-finetuned\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjDPmIOgxAsU",
        "outputId": "f264d35c-2498-4bb9-a64c-c69e24386b6a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./gpt2-finetuned/tokenizer_config.json',\n",
              " './gpt2-finetuned/special_tokens_map.json',\n",
              " './gpt2-finetuned/vocab.json',\n",
              " './gpt2-finetuned/merges.txt',\n",
              " './gpt2-finetuned/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load your fine-tuned model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"./gpt2-finetuned\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2-finetuned\")\n",
        "\n",
        "# Set pad token again (required for generation)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Create text generation pipeline\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Generate text from a prompt\n",
        "prompt = \"Once upon a time\"\n",
        "output = generator(prompt, max_length=100, num_return_sequences=1, do_sample=True, temperature=0.8)\n",
        "\n",
        "print(\"üìù Generated Text:\\n\")\n",
        "print(output[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_s6tN4uxSOj",
        "outputId": "83f72d50-5879-4948-c5aa-36d33ded38fe"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù Generated Text:\n",
            "\n",
            "Once upon a time the world had been ruled by the Roman Empire, its greatest ruler was a ruler of kings and nobles as deep as the Mediterranean. He was known at the time as the Emperor of the Roman Empire. The people living in the world were known for their wisdom and wisdom, and they were wise enough to know that his rule was good.\n",
            "\n",
            "He was known for not being a tyrant, but for being just human. He would make his decisions with a firm and decisive mind and a decisive heart. He was willing to listen to the advice of others, even if it meant risking his life to accomplish the same. His actions were pure and spontaneous, with the greatest possible amount of patience and concentration. He was a good leader who would have done anything for his people, even if it meant doing his best to avoid being caught in an act of political treason. He was a man who could always be more powerful than his opponents, and who could always take risks.\n",
            "\n",
            "But the emperor was more than just a leader. He was much more than a person. The man who was able to make decisions that others could follow, and who was willing to give his life to protect his people.\n",
            "\n",
            "In the Roman Empire, the power of a ruler was defined by his people\n"
          ]
        }
      ]
    }
  ]
}